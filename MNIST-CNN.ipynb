{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]#10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n",
      "(60000, 1, 28, 28)\n",
      "(10000, 10)\n",
      "(60000, 10)\n",
      "(3000, 1, 28, 28)\n",
      "(3000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (X_test.shape)\n",
    "print (X_train.shape)\n",
    "print (y_test.shape)\n",
    "print (y_train.shape)\n",
    "X_train1 = X_train[:3000]\n",
    "y_train1 = y_train[:3000]\n",
    "print (X_train1.shape)\n",
    "print (y_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-4b2cc4c95d78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mX_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0my_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#numpy.column_stack((y_train1, y_batch))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lingq\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "datagen.fit(X_train1,seed=3)\n",
    "i = 0\n",
    "for X_batch, y_batch in datagen.flow(X_train1, y_train1, batch_size= 50):\n",
    "    i+=1\n",
    "    X_train1 = numpy.row_stack((X_train1, X_batch))\n",
    "    y_train1 = numpy.row_stack((y_train1, y_batch))\n",
    "        #numpy.column_stack((y_train1, y_batch))\n",
    "    if i >= 3000: \n",
    "        break\n",
    "        \n",
    "print (X_train1.shape)\n",
    "print (y_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lingq\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, (5, 5), activation=\"relu\", padding=\"valid\", input_shape=(1, 28, 28...)`\n",
      "  \n",
      "C:\\Users\\lingq\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\lingq\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:834: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40s - loss: 2.0962 - acc: 0.2897 - val_loss: 1.5755 - val_acc: 0.5171\n",
      "Epoch 2/100\n",
      "43s - loss: 1.2765 - acc: 0.5743 - val_loss: 0.7616 - val_acc: 0.7697\n",
      "Epoch 3/100\n",
      "47s - loss: 0.7285 - acc: 0.7687 - val_loss: 0.4533 - val_acc: 0.8702\n",
      "Epoch 4/100\n",
      "54s - loss: 0.4928 - acc: 0.8473 - val_loss: 0.3244 - val_acc: 0.9084\n",
      "Epoch 5/100\n",
      "45s - loss: 0.3678 - acc: 0.8937 - val_loss: 0.2620 - val_acc: 0.9239\n",
      "Epoch 6/100\n",
      "43s - loss: 0.2863 - acc: 0.9213 - val_loss: 0.2224 - val_acc: 0.9335\n",
      "Epoch 7/100\n",
      "49s - loss: 0.2528 - acc: 0.9283 - val_loss: 0.2007 - val_acc: 0.9412\n",
      "Epoch 8/100\n",
      "41s - loss: 0.2135 - acc: 0.9397 - val_loss: 0.1782 - val_acc: 0.9475\n",
      "Epoch 9/100\n",
      "43s - loss: 0.1976 - acc: 0.9397 - val_loss: 0.1639 - val_acc: 0.9501\n",
      "Epoch 10/100\n",
      "43s - loss: 0.1762 - acc: 0.9497 - val_loss: 0.1710 - val_acc: 0.9504\n",
      "Epoch 11/100\n",
      "43s - loss: 0.1572 - acc: 0.9547 - val_loss: 0.1391 - val_acc: 0.9595\n",
      "Epoch 12/100\n",
      "45s - loss: 0.1463 - acc: 0.9590 - val_loss: 0.1310 - val_acc: 0.9605\n",
      "Epoch 13/100\n",
      "45s - loss: 0.1327 - acc: 0.9620 - val_loss: 0.1450 - val_acc: 0.9560\n",
      "Epoch 14/100\n",
      "43s - loss: 0.1245 - acc: 0.9617 - val_loss: 0.1204 - val_acc: 0.9651\n",
      "Epoch 15/100\n",
      "50s - loss: 0.1210 - acc: 0.9623 - val_loss: 0.1226 - val_acc: 0.9621\n",
      "Epoch 16/100\n",
      "44s - loss: 0.1135 - acc: 0.9663 - val_loss: 0.1217 - val_acc: 0.9607\n",
      "Epoch 17/100\n",
      "40s - loss: 0.0945 - acc: 0.9707 - val_loss: 0.1087 - val_acc: 0.9668\n",
      "Epoch 18/100\n",
      "39s - loss: 0.0890 - acc: 0.9730 - val_loss: 0.1070 - val_acc: 0.9662\n",
      "Epoch 19/100\n",
      "41s - loss: 0.0877 - acc: 0.9717 - val_loss: 0.1009 - val_acc: 0.9696\n",
      "Epoch 20/100\n",
      "39s - loss: 0.0808 - acc: 0.9763 - val_loss: 0.0985 - val_acc: 0.9705\n",
      "Epoch 21/100\n",
      "46s - loss: 0.0768 - acc: 0.9773 - val_loss: 0.1014 - val_acc: 0.9682\n",
      "Epoch 22/100\n",
      "41s - loss: 0.0693 - acc: 0.9773 - val_loss: 0.1139 - val_acc: 0.9656\n",
      "Epoch 23/100\n",
      "43s - loss: 0.0687 - acc: 0.9810 - val_loss: 0.0953 - val_acc: 0.9693\n",
      "Epoch 24/100\n",
      "41s - loss: 0.0658 - acc: 0.9797 - val_loss: 0.0927 - val_acc: 0.9706\n",
      "Epoch 25/100\n",
      "40s - loss: 0.0489 - acc: 0.9847 - val_loss: 0.0894 - val_acc: 0.9720\n",
      "Epoch 26/100\n",
      "46s - loss: 0.0566 - acc: 0.9833 - val_loss: 0.0934 - val_acc: 0.9697\n",
      "Epoch 27/100\n",
      "42s - loss: 0.0551 - acc: 0.9817 - val_loss: 0.0885 - val_acc: 0.9715\n",
      "Epoch 28/100\n",
      "43s - loss: 0.0568 - acc: 0.9823 - val_loss: 0.0962 - val_acc: 0.9692\n",
      "Epoch 29/100\n",
      "45s - loss: 0.0496 - acc: 0.9853 - val_loss: 0.0874 - val_acc: 0.9740\n",
      "Epoch 30/100\n",
      "44s - loss: 0.0426 - acc: 0.9853 - val_loss: 0.0924 - val_acc: 0.9733\n",
      "Epoch 31/100\n",
      "43s - loss: 0.0403 - acc: 0.9877 - val_loss: 0.0876 - val_acc: 0.9712\n",
      "Epoch 32/100\n",
      "44s - loss: 0.0437 - acc: 0.9853 - val_loss: 0.0868 - val_acc: 0.9722\n",
      "Epoch 33/100\n",
      "48s - loss: 0.0382 - acc: 0.9897 - val_loss: 0.0857 - val_acc: 0.9753\n",
      "Epoch 34/100\n",
      "46s - loss: 0.0359 - acc: 0.9873 - val_loss: 0.0846 - val_acc: 0.9727\n",
      "Epoch 35/100\n",
      "46s - loss: 0.0402 - acc: 0.9860 - val_loss: 0.0965 - val_acc: 0.9705\n",
      "Epoch 36/100\n",
      "44s - loss: 0.0356 - acc: 0.9870 - val_loss: 0.0946 - val_acc: 0.9725\n",
      "Epoch 37/100\n",
      "39s - loss: 0.0340 - acc: 0.9903 - val_loss: 0.0853 - val_acc: 0.9744\n",
      "Epoch 38/100\n",
      "45s - loss: 0.0305 - acc: 0.9900 - val_loss: 0.0879 - val_acc: 0.9735\n",
      "Larger CNN Error: 2.65%\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Convolution2D(50, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.3))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(32, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train1, y_train1, validation_data=(X_test, y_test), nb_epoch=100, batch_size=200, verbose=2, callbacks=[early_stopping])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Larger CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test on smaller size training data\n",
    "train_num=[300,600,900,1200,1500,1800] \n",
    "for n in train_num:\n",
    "    X_train1 = X_train[:n] \n",
    "    y_train1 = y_train[:n] \n",
    "    datagen = ImageDataGenerator( rotation_range=10,\n",
    "    shear_range=0.5,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest')\n",
    "    datagen.fit(X_train1) \n",
    "    i = 0 \n",
    "    for X_batch, y_batch in datagen.flow(X_train1, y_train1, batch_size= 50):\n",
    "        i+=1\n",
    "        X_train1 = numpy.row_stack((X_train1, X_batch))\n",
    "        y_train1 = numpy.row_stack((y_train1, y_batch))\n",
    "            #numpy.column_stack((y_train1, y_batch))\n",
    "        if i >= 3000: \n",
    "            break\n",
    "    model = larger_model() \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(X_train1, y_train1, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2, callbacks=[early_stopping]) \n",
    "    scores = model.evaluate(X_test, y_test, verbose=0) \n",
    "    print(\"Larger CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURGREHQSFREJ4f8DA2llq3wRtp4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de03fe3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#keras ImageDataGenerator example\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "# convert from int to float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# define data preparation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "    width_shift_range=0,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "X_show=X_train[:9]\n",
    "y_show=y_train[:9]\n",
    "# fit parameters from data\n",
    "datagen.fit(X_show)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(X_show, y_show, batch_size=9):\n",
    "\t# create a grid of 3x3 images\n",
    "\tfor i in range(0, 9):\n",
    "\t\tpyplot.subplot(330 + 1 + i)\n",
    "\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n",
    "\t# show the plot\n",
    "\tpyplot.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
